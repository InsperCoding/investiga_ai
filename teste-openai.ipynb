{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1aaaa977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5a93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar chave da API do OpenAI\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb58c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler o PDF e dividir em chunks\n",
    "def load_and_split_pdf(pdf_path):\n",
    "    # Ler o PDF\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    \n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    # Dividir o texto em chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5568bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar embeddings e armazenar em um índice FAISS\n",
    "def create_vector_store(chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f78c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI  # Certifique-se de importar a classe OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def query_rag(question, vector_store):\n",
    "    # Usando OpenAI LLM com a chave da API\n",
    "    llm = OpenAI(model_name=\"text-davinci-003\", temperature=0, openai_api_key=openai.api_key)\n",
    "    \n",
    "    # Criar a cadeia de perguntas e respostas com o retriever\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",  # Ou outro tipo dependendo do seu caso\n",
    "        retriever=vector_store.as_retriever(),\n",
    "    )\n",
    "    \n",
    "    # Obter a resposta\n",
    "    response = qa_chain.run(question)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4856b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o PDF\n",
    "pdf_path = 'modelo operadora3.pdf'\n",
    "\n",
    "# Carregar e dividir o PDF em chunks\n",
    "chunks = load_and_split_pdf(pdf_path)\n",
    "\n",
    "# Criar o vector store com os chunks\n",
    "vector_store = create_vector_store(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b0b9ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta: \n",
      "111.11.111.11 - 2000-01-11 01:01:01 UTC\n",
      "111.11.111.11 - 2000-01-11 01:01:01 UTC\n",
      "111.11.111.11 - 2000-01-11 01:01:01 UTC\n",
      "111.11.111.11 - 2000-01-11 01:01:01 UTC\n",
      "111.11.111.1 - 2000-01-11 01:01:01 UTC\n",
      "111.11.111.11 - 2000-01-11 01:01:01 UTC\n",
      "111.11.111.1 - 2000-01-11 01:01:01 UTC\n",
      "1111:11d:1e11:11bc:bc11:1111:11ba:4e11 - 2000-01-11 01:01:01 UTC\n",
      "111.11.111.1 - 2000-01-11 01:01:01 UTC\n",
      "111.11.111.1 - 2000-01-11 01:01:01 UTC\n",
      "111.11.111.1\n"
     ]
    }
   ],
   "source": [
    "# Perguntar algo sobre o PDF\n",
    "question = \"\"\"\n",
    "    You are an expert in analyzing raw logs and unstructured text. Your task is to extract **all IP addresses (IPv4 and IPv6)** and the **exact timestamp** associated with each IP.\n",
    "\n",
    "    Instructions:\n",
    "    1. From the text below, find all valid IPv4 and IPv6 addresses.\n",
    "    2. For each IP address, find the **full date and time** (timestamp) that appears **closest and most directly associated** with that IP.\n",
    "    3. Return only the IP address and its timestamp in this exact format: `IP_ADDRESS - TIMESTAMP`\n",
    "    4. Check if the IP address has a timestamp associated with it. If not, do not include it in the results.\n",
    "    5. If multiple timestamps are present near the same IP, choose the most **complete and specific one** (e.g., including date + time + timezone if possible).\n",
    "    6. Each result must be on a **separate line**.\n",
    "    7. Do NOT include any explanation, markdown, bullet points, or extra formatting.\n",
    "\n",
    "\n",
    "    Text:\n",
    "    {chunk}\n",
    "\"\"\"\n",
    "response = query_rag(question, vector_store)\n",
    "\n",
    "print(\"Resposta:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa563552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1101:11:11a:0a111:0:a11:aa11 - 2011-02-11 02:47:31 UTC\\n1101:11:11a:0a111:0:a11:aa11 - 2011-02-11 02:38:38 UTC\\n1101:11:11a:0a111:0:a11:aa11 - 2011-02-11 02:32:11 UTC\\n1101:11:11a:0a111:0:a11:aa11 - 2011-02-11 02:27:55 UTC\\n1101:11:11a:0a111:0:a11:aa11 - 2011-02-11 02:22:00 UTC\\n1101:11:11a:0a111:0:a11:aa11 - 2011-02-11 02:06:55 UTC\\n1101:11:11a:0a111:0:a11:aa11 - 2011-02-11 02:55:45 UTC\\n1101:11:11a:0a111:0:a11:aa'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d375ca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       IP                 Datetime\n",
      "0                           111.11.111.11  2000-01-11 01:01:01 UTC\n",
      "1                           111.11.111.11  2000-01-11 01:01:01 UTC\n",
      "2                           111.11.111.11  2000-01-11 01:01:01 UTC\n",
      "3                           111.11.111.11  2000-01-11 01:01:01 UTC\n",
      "4                            111.11.111.1  2000-01-11 01:01:01 UTC\n",
      "5                           111.11.111.11  2000-01-11 01:01:01 UTC\n",
      "6                            111.11.111.1  2000-01-11 01:01:01 UTC\n",
      "7  1111:11d:1e11:11bc:bc11:1111:11ba:4e11  2000-01-11 01:01:01 UTC\n",
      "8                            111.11.111.1  2000-01-11 01:01:01 UTC\n",
      "9                            111.11.111.1  2000-01-11 01:01:01 UTC\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def texto_para_df(texto):\n",
    "    # Criando uma lista de dicionários, onde cada dicionário é uma linha do DataFrame\n",
    "    dados = []\n",
    "    \n",
    "    # Dividir o texto em linhas\n",
    "    linhas = texto.split('\\n')\n",
    "    \n",
    "    for linha in linhas:\n",
    "        # Separar o texto antes de \" - \" como IP e o restante como datetime\n",
    "        partes = linha.split(' - ')\n",
    "        if len(partes) == 2:\n",
    "            ip = partes[0]\n",
    "            datetime = partes[1]\n",
    "            dados.append({\"IP\": ip, \"Datetime\": datetime})\n",
    "    \n",
    "    # Criar o DataFrame a partir da lista de dicionários\n",
    "    df = pd.DataFrame(dados)\n",
    "    return df\n",
    "\n",
    "# Texto de exemplo\n",
    "texto = response\n",
    "\n",
    "# Chamar a função\n",
    "df = texto_para_df(texto)\n",
    "\n",
    "# Exibir o DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e43b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar o df em um arquivo CSV\n",
    "df.to_csv('resultado3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3e9073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('resultado1.csv')\n",
    "df2 = pd.read_csv('resultado2.csv')\n",
    "df3 = pd.read_csv('resultado3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "926dc2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IP</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2222:011a:1b11:11cd:e1f1:g111:hh11:0ij1</td>\n",
       "      <td>01/01/11 14:35:45 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2222:011a:1b11:11cd:e1f1:g111:hh11:0ij1</td>\n",
       "      <td>01/01/11 14:35:45 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222:011a:1b11:11cd:e1f1:g111:hh11:0ij1</td>\n",
       "      <td>01/01/11 14:35:45 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        IP               Datetime\n",
       "0  2222:011a:1b11:11cd:e1f1:g111:hh11:0ij1  01/01/11 14:35:45 UTC\n",
       "1  2222:011a:1b11:11cd:e1f1:g111:hh11:0ij1  01/01/11 14:35:45 UTC\n",
       "2   222:011a:1b11:11cd:e1f1:g111:hh11:0ij1  01/01/11 14:35:45 UTC"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463eff6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "investiga_ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
